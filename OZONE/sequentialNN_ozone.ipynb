{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df955f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 11:52:58.194987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:52:58.195043: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "s3_home =  os.getcwd()\n",
    "try: sys.path.remove(s3_home) \n",
    "except Exception: pass\n",
    "current_dir = os.getcwd()\n",
    "os.chdir('DATA_PATH/ozone') \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(current_dir) \n",
    "sys.path.append(s3_home) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e5d0a",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f720b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rad_325.0_nm</th>\n",
       "      <th>rad_325.5_nm</th>\n",
       "      <th>rad_326.0_nm</th>\n",
       "      <th>rad_326.5_nm</th>\n",
       "      <th>rad_327.0_nm</th>\n",
       "      <th>rad_327.5_nm</th>\n",
       "      <th>rad_328.0_nm</th>\n",
       "      <th>rad_328.5_nm</th>\n",
       "      <th>rad_329.0_nm</th>\n",
       "      <th>rad_329.5_nm</th>\n",
       "      <th>...</th>\n",
       "      <th>rad_333.0_nm</th>\n",
       "      <th>rad_333.5_nm</th>\n",
       "      <th>rad_334.0_nm</th>\n",
       "      <th>rad_334.5_nm</th>\n",
       "      <th>rad_335.0_nm</th>\n",
       "      <th>sza</th>\n",
       "      <th>vza</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>ozone_total_column_[DU]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042720</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.064092</td>\n",
       "      <td>0.066062</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.076385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066981</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.067544</td>\n",
       "      <td>59.516346</td>\n",
       "      <td>7.200823</td>\n",
       "      <td>34.040398</td>\n",
       "      <td>15.452230</td>\n",
       "      <td>312.801062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035083</td>\n",
       "      <td>0.043096</td>\n",
       "      <td>0.052921</td>\n",
       "      <td>0.054148</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>0.045935</td>\n",
       "      <td>0.058220</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053694</td>\n",
       "      <td>0.047931</td>\n",
       "      <td>0.050669</td>\n",
       "      <td>0.055808</td>\n",
       "      <td>0.052929</td>\n",
       "      <td>58.856736</td>\n",
       "      <td>10.524595</td>\n",
       "      <td>33.157636</td>\n",
       "      <td>16.177355</td>\n",
       "      <td>311.510057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032866</td>\n",
       "      <td>0.039644</td>\n",
       "      <td>0.050325</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.047489</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>0.054030</td>\n",
       "      <td>0.059267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050887</td>\n",
       "      <td>0.047117</td>\n",
       "      <td>0.047478</td>\n",
       "      <td>0.054090</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>60.072235</td>\n",
       "      <td>14.218850</td>\n",
       "      <td>34.355670</td>\n",
       "      <td>16.398046</td>\n",
       "      <td>310.450920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034466</td>\n",
       "      <td>0.042574</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.052547</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.046973</td>\n",
       "      <td>0.042978</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.057255</td>\n",
       "      <td>0.060181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>0.045585</td>\n",
       "      <td>0.049813</td>\n",
       "      <td>0.053308</td>\n",
       "      <td>0.052190</td>\n",
       "      <td>60.109164</td>\n",
       "      <td>6.403538</td>\n",
       "      <td>34.733997</td>\n",
       "      <td>15.136957</td>\n",
       "      <td>307.712248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031162</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.047647</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>0.042522</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.052197</td>\n",
       "      <td>0.054791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047542</td>\n",
       "      <td>0.041568</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>0.047797</td>\n",
       "      <td>62.851804</td>\n",
       "      <td>5.198928</td>\n",
       "      <td>37.823663</td>\n",
       "      <td>14.033505</td>\n",
       "      <td>296.586119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.051954</td>\n",
       "      <td>0.053398</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>0.047056</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054243</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.055708</td>\n",
       "      <td>62.746115</td>\n",
       "      <td>26.651324</td>\n",
       "      <td>36.751738</td>\n",
       "      <td>17.785243</td>\n",
       "      <td>300.032216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.034575</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>0.039951</td>\n",
       "      <td>0.037723</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.035691</td>\n",
       "      <td>0.046237</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>62.784141</td>\n",
       "      <td>4.876854</td>\n",
       "      <td>37.760609</td>\n",
       "      <td>14.001978</td>\n",
       "      <td>296.118841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.033929</td>\n",
       "      <td>0.041685</td>\n",
       "      <td>0.052090</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.051815</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>0.043879</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>0.057710</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054260</td>\n",
       "      <td>0.048758</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>0.056917</td>\n",
       "      <td>0.053629</td>\n",
       "      <td>63.468435</td>\n",
       "      <td>11.365543</td>\n",
       "      <td>38.265044</td>\n",
       "      <td>14.853213</td>\n",
       "      <td>302.393093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.031069</td>\n",
       "      <td>0.038370</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.047141</td>\n",
       "      <td>0.044044</td>\n",
       "      <td>0.041472</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.039707</td>\n",
       "      <td>0.051756</td>\n",
       "      <td>0.054031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>0.040487</td>\n",
       "      <td>0.045092</td>\n",
       "      <td>0.047425</td>\n",
       "      <td>0.047548</td>\n",
       "      <td>63.734396</td>\n",
       "      <td>2.560235</td>\n",
       "      <td>38.895588</td>\n",
       "      <td>13.276852</td>\n",
       "      <td>304.393545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.034737</td>\n",
       "      <td>0.036571</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.052601</td>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.050559</td>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.060647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054277</td>\n",
       "      <td>0.054132</td>\n",
       "      <td>0.047073</td>\n",
       "      <td>0.055671</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>60.988798</td>\n",
       "      <td>23.738834</td>\n",
       "      <td>34.923160</td>\n",
       "      <td>17.753716</td>\n",
       "      <td>307.684116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rad_325.0_nm  rad_325.5_nm  rad_326.0_nm  rad_326.5_nm  rad_327.0_nm  \\\n",
       "0         0.042720      0.052927      0.064092      0.066062      0.062508   \n",
       "1         0.035083      0.043096      0.052921      0.054148      0.052210   \n",
       "2         0.032866      0.039644      0.050325      0.050918      0.050511   \n",
       "3         0.034466      0.042574      0.051158      0.052547      0.049777   \n",
       "4         0.031162      0.038639      0.046340      0.047647      0.045056   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2495      0.035029      0.034219      0.046429      0.051954      0.053398   \n",
       "2496      0.028071      0.034575      0.041262      0.042478      0.039951   \n",
       "2497      0.033929      0.041685      0.052090      0.053287      0.051815   \n",
       "2498      0.031069      0.038370      0.045653      0.047141      0.044044   \n",
       "2499      0.034737      0.036571      0.049350      0.052601      0.054825   \n",
       "\n",
       "      rad_327.5_nm  rad_328.0_nm  rad_328.5_nm  rad_329.0_nm  rad_329.5_nm  \\\n",
       "0         0.059063      0.054011      0.055656      0.072492      0.076385   \n",
       "1         0.049266      0.044553      0.045935      0.058220      0.062203   \n",
       "2         0.047489      0.042784      0.044021      0.054030      0.059267   \n",
       "3         0.046973      0.042978      0.044233      0.057255      0.060181   \n",
       "4         0.042522      0.038951      0.040127      0.052197      0.054791   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2495      0.049628      0.048426      0.044431      0.047056      0.057794   \n",
       "2496      0.037723      0.034540      0.035691      0.046237      0.048472   \n",
       "2497      0.048783      0.043879      0.045482      0.057710      0.062159   \n",
       "2498      0.041472      0.038281      0.039707      0.051756      0.054031   \n",
       "2499      0.050559      0.048035      0.046036      0.050059      0.060647   \n",
       "\n",
       "      ...  rad_333.0_nm  rad_333.5_nm  rad_334.0_nm  rad_334.5_nm  \\\n",
       "0     ...      0.066981      0.058454      0.064113      0.068836   \n",
       "1     ...      0.053694      0.047931      0.050669      0.055808   \n",
       "2     ...      0.050887      0.047117      0.047478      0.054090   \n",
       "3     ...      0.052075      0.045585      0.049813      0.053308   \n",
       "4     ...      0.047542      0.041568      0.045608      0.048783   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "2495  ...      0.054243      0.053478      0.045803      0.053406   \n",
       "2496  ...      0.041648      0.036282      0.040008      0.042476   \n",
       "2497  ...      0.054260      0.048758      0.050999      0.056917   \n",
       "2498  ...      0.046890      0.040487      0.045092      0.047425   \n",
       "2499  ...      0.054277      0.054132      0.047073      0.055671   \n",
       "\n",
       "      rad_335.0_nm        sza        vza        lat        lon  \\\n",
       "0         0.067544  59.516346   7.200823  34.040398  15.452230   \n",
       "1         0.052929  58.856736  10.524595  33.157636  16.177355   \n",
       "2         0.049683  60.072235  14.218850  34.355670  16.398046   \n",
       "3         0.052190  60.109164   6.403538  34.733997  15.136957   \n",
       "4         0.047797  62.851804   5.198928  37.823663  14.033505   \n",
       "...            ...        ...        ...        ...        ...   \n",
       "2495      0.055708  62.746115  26.651324  36.751738  17.785243   \n",
       "2496      0.041984  62.784141   4.876854  37.760609  14.001978   \n",
       "2497      0.053629  63.468435  11.365543  38.265044  14.853213   \n",
       "2498      0.047548  63.734396   2.560235  38.895588  13.276852   \n",
       "2499      0.054560  60.988798  23.738834  34.923160  17.753716   \n",
       "\n",
       "      ozone_total_column_[DU]  \n",
       "0                  312.801062  \n",
       "1                  311.510057  \n",
       "2                  310.450920  \n",
       "3                  307.712248  \n",
       "4                  296.586119  \n",
       "...                       ...  \n",
       "2495               300.032216  \n",
       "2496               296.118841  \n",
       "2497               302.393093  \n",
       "2498               304.393545  \n",
       "2499               307.684116  \n",
       "\n",
       "[2500 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"DATA_PATH/INPUT_Sentinel-5p.csv\") \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c4f37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 23), (2500, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.values[:, 0:23]\n",
    "y = dataset.values[:, 25:26]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580e5ca",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268f13ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 23), (1000, 23), (1500, 1), (1000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, \n",
    "                                                                    y, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    random_state=32)\n",
    "\n",
    "X_train.shape, X_val_and_test.shape, y_train.shape, y_val_and_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9efcc5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e099909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550, 23), (450, 23), (550, 1), (450, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, \n",
    "                                                y_val_and_test, \n",
    "                                                test_size=0.45, \n",
    "                                                random_state=32)\n",
    "\n",
    "X_val.shape, X_test.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abc966",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99097444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_scaler = MinMaxScaler(feature_range=(-5, 5))\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e66803",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b42097d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_scaler.fit(X)\n",
    "X_train_scaled = input_scaler.transform(X_train)\n",
    "X_val_scaled = input_scaler.transform(X_val)\n",
    "X_test_scaled = input_scaler.transform(X_test)\n",
    "\n",
    "output_scaler.fit(y)\n",
    "y_train_scaled = output_scaler.transform(y_train)\n",
    "y_val_scaled = output_scaler.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c47b8b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a1df58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 11:53:04.547177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-03 11:53:04.547426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547488: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547637: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547735: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-03 11:53:04.547869: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-03 11:53:04.548803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_nn_for_o3 = Sequential([Dense(units=20, \n",
    "                                    activation='sigmoid', \n",
    "                                    input_shape=(23,)),\n",
    "                              Dense(units=1, \n",
    "                                    activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22bc5f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd15d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nn_for_o3.compile(optimizer='sgd',  \n",
    "                        loss='mean_squared_error',  \n",
    "                        metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df5227",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20e9f88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0625 - mae: 0.2042 - val_loss: 0.0422 - val_mae: 0.1690\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.1702 - val_loss: 0.0375 - val_mae: 0.1579\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0385 - mae: 0.1610 - val_loss: 0.0340 - val_mae: 0.1504\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.1536 - val_loss: 0.0315 - val_mae: 0.1446\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0326 - mae: 0.1476 - val_loss: 0.0294 - val_mae: 0.1401\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0306 - mae: 0.1430 - val_loss: 0.0278 - val_mae: 0.1364\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.1390 - val_loss: 0.0265 - val_mae: 0.1332\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.1354 - val_loss: 0.0254 - val_mae: 0.1304\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1326 - val_loss: 0.0246 - val_mae: 0.1275\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.1298 - val_loss: 0.0238 - val_mae: 0.1254\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.1275 - val_loss: 0.0232 - val_mae: 0.1234\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0241 - mae: 0.1255 - val_loss: 0.0227 - val_mae: 0.1218\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0235 - mae: 0.1237 - val_loss: 0.0223 - val_mae: 0.1207\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0230 - mae: 0.1224 - val_loss: 0.0220 - val_mae: 0.1192\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.1209 - val_loss: 0.0217 - val_mae: 0.1182\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0222 - mae: 0.1197 - val_loss: 0.0214 - val_mae: 0.1178\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0219 - mae: 0.1188 - val_loss: 0.0212 - val_mae: 0.1170\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0217 - mae: 0.1180 - val_loss: 0.0210 - val_mae: 0.1159\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0215 - mae: 0.1170 - val_loss: 0.0208 - val_mae: 0.1158\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0213 - mae: 0.1166 - val_loss: 0.0207 - val_mae: 0.1150\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.1159 - val_loss: 0.0207 - val_mae: 0.1143\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.1152 - val_loss: 0.0206 - val_mae: 0.1140\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0209 - mae: 0.1146 - val_loss: 0.0205 - val_mae: 0.1139\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0208 - mae: 0.1144 - val_loss: 0.0205 - val_mae: 0.1134\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0207 - mae: 0.1137 - val_loss: 0.0203 - val_mae: 0.1134\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0206 - mae: 0.1136 - val_loss: 0.0203 - val_mae: 0.1131\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.1133 - val_loss: 0.0203 - val_mae: 0.1128\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.1131 - val_loss: 0.0203 - val_mae: 0.1124\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0204 - mae: 0.1126 - val_loss: 0.0202 - val_mae: 0.1124\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.1125 - val_loss: 0.0202 - val_mae: 0.1121\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.1122 - val_loss: 0.0202 - val_mae: 0.1120\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.1120 - val_loss: 0.0202 - val_mae: 0.1118\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.1118 - val_loss: 0.0201 - val_mae: 0.1117\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.1116 - val_loss: 0.0201 - val_mae: 0.1116\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.1114 - val_loss: 0.0201 - val_mae: 0.1116\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.1114 - val_loss: 0.0201 - val_mae: 0.1113\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.1112 - val_loss: 0.0202 - val_mae: 0.1111\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.1109 - val_loss: 0.0201 - val_mae: 0.1111\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.1107 - val_loss: 0.0200 - val_mae: 0.1113\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.1108 - val_loss: 0.0200 - val_mae: 0.1110\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.1107 - val_loss: 0.0200 - val_mae: 0.1110\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.1106 - val_loss: 0.0200 - val_mae: 0.1107\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.1104 - val_loss: 0.0199 - val_mae: 0.1108\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.1102 - val_loss: 0.0199 - val_mae: 0.1106\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.1102 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1100 - val_loss: 0.0199 - val_mae: 0.1106\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1101 - val_loss: 0.0199 - val_mae: 0.1104\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1100 - val_loss: 0.0198 - val_mae: 0.1104\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1098 - val_loss: 0.0198 - val_mae: 0.1104\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1098 - val_loss: 0.0198 - val_mae: 0.1102\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0198 - mae: 0.1098 - val_loss: 0.0198 - val_mae: 0.1101\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0198 - mae: 0.1096 - val_loss: 0.0198 - val_mae: 0.1101\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1096 - val_loss: 0.0198 - val_mae: 0.1099\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1095 - val_loss: 0.0198 - val_mae: 0.1099\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1094 - val_loss: 0.0197 - val_mae: 0.1100\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1094 - val_loss: 0.0197 - val_mae: 0.1099\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.1094 - val_loss: 0.0197 - val_mae: 0.1097\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0197 - mae: 0.1093 - val_loss: 0.0197 - val_mae: 0.1096\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.1092 - val_loss: 0.0197 - val_mae: 0.1096\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0197 - mae: 0.1092 - val_loss: 0.0197 - val_mae: 0.1095\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0197 - mae: 0.1092 - val_loss: 0.0197 - val_mae: 0.1095\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1091 - val_loss: 0.0197 - val_mae: 0.1094\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1091 - val_loss: 0.0196 - val_mae: 0.1094\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1090 - val_loss: 0.0196 - val_mae: 0.1095\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1090 - val_loss: 0.0196 - val_mae: 0.1093\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1088 - val_loss: 0.0195 - val_mae: 0.1094\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.1087 - val_loss: 0.0195 - val_mae: 0.1095\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1089 - val_loss: 0.0195 - val_mae: 0.1093\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1089 - val_loss: 0.0195 - val_mae: 0.1092\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.1088 - val_loss: 0.0195 - val_mae: 0.1092\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1087 - val_loss: 0.0194 - val_mae: 0.1092\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1087 - val_loss: 0.0195 - val_mae: 0.1090\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1086 - val_loss: 0.0194 - val_mae: 0.1091\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.1087 - val_loss: 0.0194 - val_mae: 0.1089\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.1085 - val_loss: 0.0194 - val_mae: 0.1090\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1084 - val_loss: 0.0193 - val_mae: 0.1092\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1086 - val_loss: 0.0193 - val_mae: 0.1091\n",
      "Epoch 78/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1085 - val_loss: 0.0193 - val_mae: 0.1089\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1084 - val_loss: 0.0193 - val_mae: 0.1090\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1085 - val_loss: 0.0193 - val_mae: 0.1087\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.1083 - val_loss: 0.0193 - val_mae: 0.1087\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.1083 - val_loss: 0.0193 - val_mae: 0.1087\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.1083 - val_loss: 0.0193 - val_mae: 0.1086\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.1082 - val_loss: 0.0193 - val_mae: 0.1086\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.1081 - val_loss: 0.0192 - val_mae: 0.1087\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.1082 - val_loss: 0.0192 - val_mae: 0.1086\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0193 - mae: 0.1081 - val_loss: 0.0192 - val_mae: 0.1085\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1081 - val_loss: 0.0192 - val_mae: 0.1085\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1080 - val_loss: 0.0191 - val_mae: 0.1085\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0192 - mae: 0.1081 - val_loss: 0.0192 - val_mae: 0.1083\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1077 - val_loss: 0.0191 - val_mae: 0.1086\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1081 - val_loss: 0.0192 - val_mae: 0.1082\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0192 - mae: 0.1080 - val_loss: 0.0191 - val_mae: 0.1083\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1079 - val_loss: 0.0191 - val_mae: 0.1083\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1079 - val_loss: 0.0191 - val_mae: 0.1082\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0191 - mae: 0.1077 - val_loss: 0.0190 - val_mae: 0.1083\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.1078 - val_loss: 0.0190 - val_mae: 0.1081\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.1078 - val_loss: 0.0191 - val_mae: 0.1080\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.1076 - val_loss: 0.0190 - val_mae: 0.1081\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.1077 - val_loss: 0.0190 - val_mae: 0.1080\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.1076 - val_loss: 0.0190 - val_mae: 0.1080\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0190 - mae: 0.1075 - val_loss: 0.0189 - val_mae: 0.1080\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.1076 - val_loss: 0.0190 - val_mae: 0.1078\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.1075 - val_loss: 0.0189 - val_mae: 0.1079\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0190 - mae: 0.1075 - val_loss: 0.0189 - val_mae: 0.1078\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.1074 - val_loss: 0.0189 - val_mae: 0.1078\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.1074 - val_loss: 0.0189 - val_mae: 0.1078\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.1074 - val_loss: 0.0189 - val_mae: 0.1077\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.1074 - val_loss: 0.0189 - val_mae: 0.1076\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.1073 - val_loss: 0.0188 - val_mae: 0.1076\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.1073 - val_loss: 0.0188 - val_mae: 0.1075\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.1073 - val_loss: 0.0189 - val_mae: 0.1075\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.1072 - val_loss: 0.0188 - val_mae: 0.1075\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.1071 - val_loss: 0.0187 - val_mae: 0.1076\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.1071 - val_loss: 0.0187 - val_mae: 0.1076\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.1072 - val_loss: 0.0188 - val_mae: 0.1073\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.1070 - val_loss: 0.0187 - val_mae: 0.1073\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.1068 - val_loss: 0.0187 - val_mae: 0.1075\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.1070 - val_loss: 0.0186 - val_mae: 0.1074\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.1070 - val_loss: 0.0187 - val_mae: 0.1072\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.1069 - val_loss: 0.0186 - val_mae: 0.1072\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1068 - val_loss: 0.0186 - val_mae: 0.1072\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1068 - val_loss: 0.0187 - val_mae: 0.1071\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1069 - val_loss: 0.0187 - val_mae: 0.1070\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1067 - val_loss: 0.0186 - val_mae: 0.1071\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.1068 - val_loss: 0.0185 - val_mae: 0.1071\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0187 - mae: 0.1067 - val_loss: 0.0185 - val_mae: 0.1070\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.1066 - val_loss: 0.0185 - val_mae: 0.1070\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0186 - mae: 0.1067 - val_loss: 0.0185 - val_mae: 0.1069\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0186 - mae: 0.1066 - val_loss: 0.0185 - val_mae: 0.1069\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1066 - val_loss: 0.0185 - val_mae: 0.1068\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1065 - val_loss: 0.0185 - val_mae: 0.1068\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1065 - val_loss: 0.0185 - val_mae: 0.1067\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1065 - val_loss: 0.0184 - val_mae: 0.1067\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1064 - val_loss: 0.0184 - val_mae: 0.1066\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0184 - val_mae: 0.1067\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0183 - val_mae: 0.1068\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.1064 - val_loss: 0.0183 - val_mae: 0.1066\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0183 - val_mae: 0.1065\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0183 - val_mae: 0.1065\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.1062 - val_loss: 0.0183 - val_mae: 0.1064\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.1062 - val_loss: 0.0183 - val_mae: 0.1064\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1061 - val_loss: 0.0183 - val_mae: 0.1064\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1061 - val_loss: 0.0183 - val_mae: 0.1063\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1060 - val_loss: 0.0182 - val_mae: 0.1064\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1060 - val_loss: 0.0182 - val_mae: 0.1064\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1061 - val_loss: 0.0182 - val_mae: 0.1063\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1060 - val_loss: 0.0182 - val_mae: 0.1061\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.1059 - val_loss: 0.0182 - val_mae: 0.1061\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.1058 - val_loss: 0.0181 - val_mae: 0.1062\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.1059 - val_loss: 0.0182 - val_mae: 0.1060\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.1059 - val_loss: 0.0182 - val_mae: 0.1059\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.1058 - val_loss: 0.0182 - val_mae: 0.1059\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.1058 - val_loss: 0.0182 - val_mae: 0.1058\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.1057 - val_loss: 0.0181 - val_mae: 0.1059\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1056 - val_loss: 0.0180 - val_mae: 0.1059\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1057 - val_loss: 0.0180 - val_mae: 0.1058\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1056 - val_loss: 0.0180 - val_mae: 0.1058\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1057 - val_loss: 0.0180 - val_mae: 0.1057\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1056 - val_loss: 0.0180 - val_mae: 0.1057\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1056 - val_loss: 0.0180 - val_mae: 0.1056\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1055 - val_loss: 0.0180 - val_mae: 0.1056\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1054 - val_loss: 0.0180 - val_mae: 0.1055\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.1053 - val_loss: 0.0179 - val_mae: 0.1055\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1054 - val_loss: 0.0180 - val_mae: 0.1055\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1053 - val_loss: 0.0179 - val_mae: 0.1055\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1053 - val_loss: 0.0179 - val_mae: 0.1055\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.1053 - val_loss: 0.0179 - val_mae: 0.1054\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1052 - val_loss: 0.0179 - val_mae: 0.1053\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1052 - val_loss: 0.0179 - val_mae: 0.1053\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1052 - val_loss: 0.0179 - val_mae: 0.1052\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1050 - val_loss: 0.0178 - val_mae: 0.1052\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1050 - val_loss: 0.0178 - val_mae: 0.1051\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1050 - val_loss: 0.0178 - val_mae: 0.1051\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.1051 - val_loss: 0.0178 - val_mae: 0.1051\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1050 - val_loss: 0.0178 - val_mae: 0.1050\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1049 - val_loss: 0.0178 - val_mae: 0.1050\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1050 - val_loss: 0.0178 - val_mae: 0.1049\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1047 - val_loss: 0.0177 - val_mae: 0.1050\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1048 - val_loss: 0.0177 - val_mae: 0.1048\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1048 - val_loss: 0.0177 - val_mae: 0.1049\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1048 - val_loss: 0.0177 - val_mae: 0.1048\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1047 - val_loss: 0.0176 - val_mae: 0.1048\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1048 - val_loss: 0.0177 - val_mae: 0.1047\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1046 - val_loss: 0.0176 - val_mae: 0.1047\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1046 - val_loss: 0.0176 - val_mae: 0.1046\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1046 - val_loss: 0.0176 - val_mae: 0.1046\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1045 - val_loss: 0.0176 - val_mae: 0.1045\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.1045 - val_loss: 0.0175 - val_mae: 0.1046\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1045 - val_loss: 0.0175 - val_mae: 0.1045\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1044 - val_loss: 0.0175 - val_mae: 0.1044\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1044 - val_loss: 0.0175 - val_mae: 0.1044\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1044 - val_loss: 0.0175 - val_mae: 0.1044\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1043 - val_loss: 0.0175 - val_mae: 0.1044\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1043 - val_loss: 0.0174 - val_mae: 0.1043\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0174 - val_mae: 0.1044\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0174 - val_mae: 0.1042\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1042 - val_loss: 0.0174 - val_mae: 0.1042\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0175 - val_mae: 0.1041\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0174 - val_mae: 0.1041\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0174 - val_mae: 0.1041\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0173 - val_mae: 0.1041\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0173 - val_mae: 0.1040\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1040 - val_loss: 0.0174 - val_mae: 0.1039\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1039 - val_loss: 0.0173 - val_mae: 0.1040\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1039 - val_loss: 0.0173 - val_mae: 0.1040\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1039 - val_loss: 0.0173 - val_mae: 0.1038\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1039 - val_loss: 0.0173 - val_mae: 0.1038\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1038 - val_loss: 0.0172 - val_mae: 0.1038\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.1038 - val_loss: 0.0172 - val_mae: 0.1037\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1038 - val_loss: 0.0173 - val_mae: 0.1036\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1037 - val_loss: 0.0172 - val_mae: 0.1036\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1037 - val_loss: 0.0172 - val_mae: 0.1036\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1036 - val_loss: 0.0172 - val_mae: 0.1036\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1036 - val_loss: 0.0172 - val_mae: 0.1035\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1035 - val_loss: 0.0171 - val_mae: 0.1036\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1035 - val_loss: 0.0172 - val_mae: 0.1034\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.1035 - val_loss: 0.0172 - val_mae: 0.1034\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1035 - val_loss: 0.0171 - val_mae: 0.1033\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1035 - val_loss: 0.0171 - val_mae: 0.1033\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1034 - val_loss: 0.0171 - val_mae: 0.1033\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1034 - val_loss: 0.0171 - val_mae: 0.1033\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1033 - val_loss: 0.0171 - val_mae: 0.1032\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1034 - val_loss: 0.0170 - val_mae: 0.1032\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1033 - val_loss: 0.0170 - val_mae: 0.1031\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1032 - val_loss: 0.0170 - val_mae: 0.1031\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1032 - val_loss: 0.0170 - val_mae: 0.1031\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1032 - val_loss: 0.0170 - val_mae: 0.1030\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1032 - val_loss: 0.0169 - val_mae: 0.1030\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1032 - val_loss: 0.0170 - val_mae: 0.1030\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1031 - val_loss: 0.0169 - val_mae: 0.1030\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.1030 - val_loss: 0.0169 - val_mae: 0.1029\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1031 - val_loss: 0.0169 - val_mae: 0.1028\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1029 - val_loss: 0.0169 - val_mae: 0.1028\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1029 - val_loss: 0.0169 - val_mae: 0.1028\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1029 - val_loss: 0.0169 - val_mae: 0.1027\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1029 - val_loss: 0.0169 - val_mae: 0.1027\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1029 - val_loss: 0.0169 - val_mae: 0.1026\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.1028 - val_loss: 0.0168 - val_mae: 0.1027\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.1028 - val_loss: 0.0168 - val_mae: 0.1026\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.1028 - val_loss: 0.0168 - val_mae: 0.1026\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.1027 - val_loss: 0.0168 - val_mae: 0.1026\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.1027 - val_loss: 0.0167 - val_mae: 0.1025\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.1027 - val_loss: 0.0167 - val_mae: 0.1025\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.1026 - val_loss: 0.0167 - val_mae: 0.1025\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.1026 - val_loss: 0.0167 - val_mae: 0.1024\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1025 - val_loss: 0.0168 - val_mae: 0.1023\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1023 - val_loss: 0.0167 - val_mae: 0.1024\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1026 - val_loss: 0.0167 - val_mae: 0.1022\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1023 - val_loss: 0.0166 - val_mae: 0.1022\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1024 - val_loss: 0.0166 - val_mae: 0.1022\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1024 - val_loss: 0.0166 - val_mae: 0.1022\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1023 - val_loss: 0.0166 - val_mae: 0.1021\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1022 - val_loss: 0.0166 - val_mae: 0.1021\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1022 - val_loss: 0.0166 - val_mae: 0.1020\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1022 - val_loss: 0.0166 - val_mae: 0.1020\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.1022 - val_loss: 0.0166 - val_mae: 0.1020\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1019\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.1021 - val_loss: 0.0165 - val_mae: 0.1019\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.1021 - val_loss: 0.0166 - val_mae: 0.1019\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.1021 - val_loss: 0.0165 - val_mae: 0.1018\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1018\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1018\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1017\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1017\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.1019 - val_loss: 0.0165 - val_mae: 0.1017\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.1019 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.1019 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.1018 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.1018 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.1017 - val_loss: 0.0164 - val_mae: 0.1015\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.1017 - val_loss: 0.0164 - val_mae: 0.1015\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.1017 - val_loss: 0.0164 - val_mae: 0.1014\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1017 - val_loss: 0.0163 - val_mae: 0.1014\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1016 - val_loss: 0.0164 - val_mae: 0.1014\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1016 - val_loss: 0.0163 - val_mae: 0.1013\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1016 - val_loss: 0.0163 - val_mae: 0.1013\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1015 - val_loss: 0.0163 - val_mae: 0.1013\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.1015 - val_loss: 0.0163 - val_mae: 0.1012\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1015 - val_loss: 0.0163 - val_mae: 0.1012\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1014 - val_loss: 0.0163 - val_mae: 0.1012\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1014 - val_loss: 0.0163 - val_mae: 0.1011\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1014 - val_loss: 0.0162 - val_mae: 0.1011\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1014 - val_loss: 0.0162 - val_mae: 0.1011\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1013 - val_loss: 0.0162 - val_mae: 0.1010\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1012 - val_loss: 0.0161 - val_mae: 0.1011\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1012 - val_loss: 0.0161 - val_mae: 0.1011\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1012 - val_loss: 0.0162 - val_mae: 0.1009\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1012 - val_loss: 0.0162 - val_mae: 0.1009\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1012 - val_loss: 0.0161 - val_mae: 0.1009\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1011 - val_loss: 0.0161 - val_mae: 0.1008\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1011 - val_loss: 0.0161 - val_mae: 0.1008\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1011 - val_loss: 0.0162 - val_mae: 0.1008\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1011 - val_loss: 0.0161 - val_mae: 0.1007\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1011 - val_loss: 0.0161 - val_mae: 0.1007\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1010 - val_loss: 0.0161 - val_mae: 0.1007\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1010 - val_loss: 0.0161 - val_mae: 0.1006\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.1010 - val_loss: 0.0160 - val_mae: 0.1006\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.1010 - val_loss: 0.0160 - val_mae: 0.1006\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.1009 - val_loss: 0.0160 - val_mae: 0.1005\n",
      "Training time  107.948 s\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "hist = model_nn_for_o3.fit(X_train_scaled, \n",
    "                           y_train_scaled, \n",
    "                           batch_size=10, \n",
    "                           epochs=300, \n",
    "                           validation_data=(X_val_scaled, y_val_scaled), \n",
    "                           verbose=1)\n",
    "\n",
    "end_training = time.time()\n",
    "print(\"Training time \", round((end_training - start_training), 3), \"s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d8cc1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f789510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2973a35",
   "metadata": {},
   "source": [
    "Plot the `mean absolute error` during the training epochs by plotting `mae` and `val_mae` metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cfa8c68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['mae'])\n",
    "plt.plot(hist.history['val_mae'])\n",
    "plt.title('Model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd2346",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4740a39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6831615 ],\n",
       "       [0.36344427],\n",
       "       [0.6574628 ],\n",
       "       ...,\n",
       "       [0.3362277 ],\n",
       "       [0.3153641 ],\n",
       "       [0.4019596 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train = model_nn_for_o3.predict(X_train_scaled)\n",
    "predict_val = model_nn_for_o3.predict(X_val_scaled)\n",
    "predict_test = model_nn_for_o3.predict(X_test_scaled)\n",
    "predict_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066da33",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a881080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[309.8474 ],\n",
       "       [302.0669 ],\n",
       "       [309.22202],\n",
       "       ...,\n",
       "       [301.40454],\n",
       "       [300.89682],\n",
       "       [303.00418]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train_inverse = output_scaler.inverse_transform(predict_train)\n",
    "predict_val_inverse = output_scaler.inverse_transform(predict_val)\n",
    "predict_test_inverse = output_scaler.inverse_transform(predict_test)\n",
    "predict_train_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863bd92",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aec2afea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nn_for_o3.save(\"DATA_PATH/model_ozone.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee93472",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0179b6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 2.397 DU, Val MAE: 2.383 DU, Test MAE: 2.471 DU\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(y_train, predict_train_inverse)\n",
    "mae_val = mean_absolute_error(y_val, predict_val_inverse)\n",
    "mae_test = mean_absolute_error(y_test, predict_test_inverse)\n",
    "\n",
    "print(f'Train MAE: {round(mae_train, 3)} DU, Val MAE: {round(mae_val, 3)} DU, Test MAE: {round(mae_test, 3)} DU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb4881",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872c2672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.043 DU, Val RMSE: 3.009 DU, Test RMSE: 3.117 DU\n"
     ]
    }
   ],
   "source": [
    "rmse_train = mean_squared_error(y_train, predict_train_inverse, squared=False)\n",
    "rmse_val = mean_squared_error(y_val, predict_val_inverse, squared=False)\n",
    "rmse_test = mean_squared_error(y_test, predict_test_inverse, squared=False)\n",
    "\n",
    "print(f'Train RMSE: {round(rmse_train, 3)} DU, Val RMSE: {round(rmse_val, 3)} DU, Test RMSE: {round(rmse_test, 3)} DU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4559594",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50957585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pearson: 0.797, Val Pearson: 0.786, Test Pearson: 0.808\n"
     ]
    }
   ],
   "source": [
    "pearson_train = np.sqrt(r2_score(y_train, predict_train_inverse))\n",
    "pearson_val = np.sqrt(r2_score(y_val, predict_val_inverse))\n",
    "pearson_test = np.sqrt(r2_score(y_test, predict_test_inverse))\n",
    "\n",
    "print(f'Train Pearson: {round(pearson_train, 3)}, Val Pearson: {round(pearson_val, 3)}, Test Pearson: {round(pearson_test, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428b695",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89962d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d9656",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
